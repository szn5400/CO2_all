{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOq7fQdE5jvv98Z+MEnqJxT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szn5400/CO2_all/blob/main/gradienttape_for_grad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uhvJsRE_W9zc"
      },
      "outputs": [],
      "source": [
        "X = [[2,2],[3,3],[4,4],[5,5],[6,6],[7,7]]\n",
        "Y = [[4,4],[6,6],[8,8],[10,10],[12,12],[14,14]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size_input = 2\n",
        "size_hidden = 1\n",
        "size_output = 2\n",
        "number_of_train_examples = 2\n",
        "number_of_test_examples = 2"
      ],
      "metadata": {
        "id": "FtPe2TNeXL4p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(43)\n",
        "tf.random.set_seed(43)\n"
      ],
      "metadata": {
        "id": "mKsHX2COXb7-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden1: int, size of hidden layer 1\n",
        "    size_hidden2: int, size of hodden layer 2\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden]))\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.b1, self.b2]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)\n",
        "    loss1 =  tf.losses.mean_squared_error(y_true_tf, y_pred_tf)\n",
        "\n",
        "    '''\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted_out1 = self.forward(self.X)[:,0]\n",
        "      print('\\n\\n we are here')\n",
        "      print('predicted_out1', predicted_out1)\n",
        "      print(self.X[:,1])\n",
        "      #grad_gas_with_time = tape.gradient(predicted_out1,self.X[:,1])\n",
        "      grad_gas_with_time = tape.gradient(self.forward(self.X)[:,0],self.X[:,1])\n",
        "      print('gard values',grad_gas_with_time)\n",
        "    '''\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      predicted_out1 = tf.cast(self.forward(self.X), tf.float64)\n",
        "      print('\\n\\n we are here')\n",
        "      print('predicted_out1', predicted_out1)\n",
        "      print(self.X[:,1])\n",
        "      grad_gas_with_time = tape.gradient(predicted_out1,tf.cast(self.X, tf.float64))\n",
        "    #grad_gas_with_time = tape.gradient(self.forward(self.X),self.X)\n",
        "    print('gard values',grad_gas_with_time)\n",
        "\n",
        "    return loss1\n",
        "\n",
        "  def accuracy(self, y_pred, y_true):\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)\n",
        "    correct_pred = tf.reduce_sum(tf.abs(y_true_tf-y_pred_tf))  \n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
        "    return accuracy\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    self.X = tf.Variable(X_tf)\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    output = tf.nn.softmax(output)\n",
        "    print(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "K7l2Z8U5XiU8"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 2"
      ],
      "metadata": {
        "id": "CJgcNTcpY94E"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden, size_output, device='gpu')\n",
        "\n",
        "# Array to store accuracy and loss\n",
        "loss_with_epoch = []\n",
        "acc_with_epoch = []\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  ac = 0\n",
        "  count = 0\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X, Y)).shuffle(25, seed=epoch*(1234)).batch(2)\n",
        "  for inputs, outputs in train_ds:\n",
        "    inputs = tf.Variable(inputs)\n",
        "    print('input output', inputs, outputs)\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    ac = ac+mlp_on_cpu.accuracy(preds, outputs)\n",
        "    #ac = mlp_on_cpu.accuracy(preds, outputs)\n",
        "    count += 1\n",
        "  print('Number of Epoch = {} - Average celoss:= {}- Acc:= {} '.format(epoch + 1, np.sum(loss_total) / len(X), ac/count))\n",
        "  loss_with_epoch.append(np.sum(loss_total) / len(X))\n",
        "  acc_with_epoch.append(ac/count)\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UOYvqAxZBxC",
        "outputId": "6512261b-9cca-4cfb-f47c-fe77246438c4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input output <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
            "array([[2, 2],\n",
            "       [4, 4]], dtype=int32)> tf.Tensor(\n",
            "[[4 4]\n",
            " [8 8]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0.17756766 0.8224323 ]\n",
            " [0.17756766 0.8224323 ]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17756766 0.8224323 ]\n",
            " [0.17756766 0.8224323 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17756766 0.82243228]\n",
            " [0.17756766 0.82243228]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([2. 4.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.17756766 0.8224323 ]\n",
            " [0.17756766 0.8224323 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17756766 0.82243228]\n",
            " [0.17756766 0.82243228]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([2. 4.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.17756766 0.8224323 ]\n",
            " [0.17756766 0.8224323 ]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17756766 0.8224323 ]\n",
            " [0.17756766 0.8224323 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17756766 0.82243228]\n",
            " [0.17756766 0.82243228]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([2. 4.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "input output <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
            "array([[3, 3],\n",
            "       [6, 6]], dtype=int32)> tf.Tensor(\n",
            "[[ 6  6]\n",
            " [12 12]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0.17811847 0.82188153]\n",
            " [0.17811847 0.82188153]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17811847 0.82188153]\n",
            " [0.17811847 0.82188153]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17811847 0.82188153]\n",
            " [0.17811847 0.82188153]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([3. 6.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.17811847 0.82188153]\n",
            " [0.17811847 0.82188153]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17811847 0.82188153]\n",
            " [0.17811847 0.82188153]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([3. 6.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.17811847 0.82188153]\n",
            " [0.17811847 0.82188153]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17811847 0.82188153]\n",
            " [0.17811847 0.82188153]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17811847 0.82188153]\n",
            " [0.17811847 0.82188153]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([3. 6.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "input output <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
            "array([[5, 5],\n",
            "       [7, 7]], dtype=int32)> tf.Tensor(\n",
            "[[10 10]\n",
            " [14 14]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0.17867099 0.82132906]\n",
            " [0.17867099 0.82132906]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17867099 0.82132906]\n",
            " [0.17867099 0.82132906]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17867099 0.82132906]\n",
            " [0.17867099 0.82132906]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([5. 7.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.17867099 0.82132906]\n",
            " [0.17867099 0.82132906]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17867099 0.82132906]\n",
            " [0.17867099 0.82132906]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([5. 7.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.17867099 0.82132906]\n",
            " [0.17867099 0.82132906]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17867099 0.82132906]\n",
            " [0.17867099 0.82132906]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17867099 0.82132906]\n",
            " [0.17867099 0.82132906]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([5. 7.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "Number of Epoch = 1 - Average celoss:= 84.02027384440105- Acc:= 34.0 \n",
            "input output <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
            "array([[7, 7],\n",
            "       [5, 5]], dtype=int32)> tf.Tensor(\n",
            "[[14 14]\n",
            " [10 10]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0.17922524 0.8207748 ]\n",
            " [0.17922524 0.8207748 ]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17922524 0.8207748 ]\n",
            " [0.17922524 0.8207748 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17922524 0.82077479]\n",
            " [0.17922524 0.82077479]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([7. 5.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.17922524 0.8207748 ]\n",
            " [0.17922524 0.8207748 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17922524 0.82077479]\n",
            " [0.17922524 0.82077479]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([7. 5.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.17922524 0.8207748 ]\n",
            " [0.17922524 0.8207748 ]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17922524 0.8207748 ]\n",
            " [0.17922524 0.8207748 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17922524 0.82077479]\n",
            " [0.17922524 0.82077479]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([7. 5.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "input output <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
            "array([[6, 6],\n",
            "       [2, 2]], dtype=int32)> tf.Tensor(\n",
            "[[12 12]\n",
            " [ 4  4]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0.17978124 0.8202188 ]\n",
            " [0.17978124 0.8202188 ]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17978124 0.8202188 ]\n",
            " [0.17978124 0.8202188 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17978124 0.8202188 ]\n",
            " [0.17978124 0.8202188 ]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([6. 2.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.17978124 0.8202188 ]\n",
            " [0.17978124 0.8202188 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17978124 0.8202188 ]\n",
            " [0.17978124 0.8202188 ]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([6. 2.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.17978124 0.8202188 ]\n",
            " [0.17978124 0.8202188 ]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.17978124 0.8202188 ]\n",
            " [0.17978124 0.8202188 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.17978124 0.8202188 ]\n",
            " [0.17978124 0.8202188 ]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([6. 2.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "input output <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
            "array([[3, 3],\n",
            "       [4, 4]], dtype=int32)> tf.Tensor(\n",
            "[[6 6]\n",
            " [8 8]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0.18033893 0.8196611 ]\n",
            " [0.18033893 0.8196611 ]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.18033893 0.8196611 ]\n",
            " [0.18033893 0.8196611 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.18033893 0.81966108]\n",
            " [0.18033893 0.81966108]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([3. 4.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.18033893 0.8196611 ]\n",
            " [0.18033893 0.8196611 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.18033893 0.81966108]\n",
            " [0.18033893 0.81966108]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([3. 4.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "tf.Tensor(\n",
            "[[0.18033893 0.8196611 ]\n",
            " [0.18033893 0.8196611 ]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.18033893 0.8196611 ]\n",
            " [0.18033893 0.8196611 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "\n",
            " we are here\n",
            "predicted_out1 tf.Tensor(\n",
            "[[0.18033893 0.81966108]\n",
            " [0.18033893 0.81966108]], shape=(2, 2), dtype=float64)\n",
            "tf.Tensor([3. 4.], shape=(2,), dtype=float32)\n",
            "gard values None\n",
            "Number of Epoch = 2 - Average celoss:= 84.01920572916667- Acc:= 34.0 \n",
            "\n",
            "Total time taken (in seconds): 0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HMczIrcLZQhS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}