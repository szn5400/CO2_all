{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szn5400/CO2_all/blob/main/Copy_of_PINN_trial_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrzYQAG_xGuH",
        "outputId": "89defad3-2c82-4f4b-d9e1-fc73010f5115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files: ['/content/drive/MyDrive/data/k1r1-h.out', '/content/drive/MyDrive/data/k1r2-h.out', '/content/drive/MyDrive/data/k1r3-h.out', '/content/drive/MyDrive/data/k1r4-h.out', '/content/drive/MyDrive/data/k1r5-h.out', '/content/drive/MyDrive/data/k1r6-h.out', '/content/drive/MyDrive/data/k1r7-h.out', '/content/drive/MyDrive/data/k1r8-h.out', '/content/drive/MyDrive/data/k1r9-h.out', '/content/drive/MyDrive/data/k2r1-h.out', '/content/drive/MyDrive/data/k2r2-h.out', '/content/drive/MyDrive/data/k2r3-h.out', '/content/drive/MyDrive/data/k2r4-h.out', '/content/drive/MyDrive/data/k2r5-h.out', '/content/drive/MyDrive/data/k2r6-h.out', '/content/drive/MyDrive/data/k2r7-h.out', '/content/drive/MyDrive/data/k2r8-h.out', '/content/drive/MyDrive/data/k2r9-h.out', '/content/drive/MyDrive/data/k3r1-h.out', '/content/drive/MyDrive/data/k3r2-h.out', '/content/drive/MyDrive/data/k3r3-h.out', '/content/drive/MyDrive/data/k3r4-h.out', '/content/drive/MyDrive/data/k3r5-h.out', '/content/drive/MyDrive/data/k3r6-h.out', '/content/drive/MyDrive/data/k3r7-h.out', '/content/drive/MyDrive/data/k3r8-h.out', '/content/drive/MyDrive/data/k3r9-h.out']\n",
            "Processing file:  /content/drive/MyDrive/data/k1r1-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r2-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r3-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r4-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r5-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r6-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r7-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r8-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r9-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r1-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r2-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r3-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r4-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r5-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r6-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r7-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r8-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r9-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r1-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r2-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r3-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r4-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r5-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r6-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r7-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r8-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r9-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Ks [[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]]\n",
            "Rs [[0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]\n",
            " [0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]\n",
            " [0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]]\n",
            "debug2: (27, 71, 25, 25, 3)\n",
            "(27, 72, 25, 25, 3)\n",
            "debug2: (27, 71, 25, 25, 3)\n",
            "(27, 72, 25, 25, 3)\n",
            "debug2: (27, 71, 25, 25, 3)\n",
            "(27, 72, 25, 25, 3)\n",
            "debug2: (27, 71, 25, 25, 3)\n",
            "(27, 71)\n",
            "debug2: (27, 71)\n",
            "(27, 71)\n",
            "start\n",
            "end\n",
            "(3594375, 7)\n",
            "(3594375, 3)\n",
            "(3594375, 1)\n",
            "(3594375, 1)\n",
            "(3594375, 1)\n",
            "(3195000, 7)\n",
            "(3195000, 3)\n",
            "(3195000, 1)\n",
            "(3195000, 1)\n",
            "(3195000, 1)\n",
            "(399375, 7)\n",
            "(399375, 3)\n",
            "(399375, 1)\n",
            "(399375, 1)\n",
            "(399375, 1)\n"
          ]
        }
      ],
      "source": [
        "#for mtt (MLP)  \n",
        "\n",
        "#MTT Paper reimplementation with all data taken for rescaling rather than just training data\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/code/MLP')\n",
        "\n",
        "from read_data_unscaled import read\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from read_model import MLP_multiple\n",
        "from data_to_numpy_unscaled import numpy_multi\n",
        "\n",
        "\n",
        "#read data\n",
        "all_pressures,all_saturations,all_permeabilities,all_porosities,all_surf_inj_rate_series,all_surf_prod_rate_series,Ks,Rs = read()\n",
        "\n",
        "#convert to numpy\n",
        "features1_tr,features2_tr,target1_tr,target2_tr,target3_tr,features1_te,features2_te,target1_te,target2_te,target3_te,min_target1,max_target1,min_target2,max_target2,min_target3,max_target3 = numpy_multi(all_pressures,all_saturations,all_permeabilities,all_porosities,all_surf_inj_rate_series,all_surf_prod_rate_series,Ks,Rs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poo9FG_pxSqL",
        "outputId": "7614a593-669c-4061-deb1-e989499b73bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3195000\n"
          ]
        }
      ],
      "source": [
        "print(len(target3_tr))\n",
        "target_tr = [[0 for j in range(3)] for i in range(len(target1_tr))]\n",
        "for i in range(len(target1_tr)):\n",
        "  target_tr[i][0] = target1_tr[i]\n",
        "  target_tr[i][1] = target2_tr[i]\n",
        "  target_tr[i][2] = target3_tr[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22NTCiAOyS_P",
        "outputId": "a98fc0f6-8907-4e7d-d586-9d245c04a8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (3195000, 7)\n",
            "Y_train: (3195000, 3)\n"
          ]
        }
      ],
      "source": [
        "target_tr = np.asarray(target_tr)\n",
        "target_tr = target_tr.reshape(3195000,3)\n",
        "print('X_train: ' + str(features1_tr.shape))\n",
        "print('Y_train: ' + str(target_tr.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O_g4MU9gyuwm"
      },
      "outputs": [],
      "source": [
        "size_input = 7\n",
        "size_hidden1 = 128\n",
        "size_hidden2 = 64\n",
        "size_hidden3 = 32\n",
        "size_hidden4 = 16\n",
        "size_hidden5 = 8\n",
        "size_output = 3\n",
        "number_of_train_examples = 3195000\n",
        "number_of_test_examples = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ejwJr14vy12O"
      },
      "outputs": [],
      "source": [
        "X_train = features1_tr[:number_of_train_examples,:]\n",
        "y_train = target_tr[:number_of_train_examples,:]\n",
        "#X_test = features1_tr[number_of_train_examples:number_of_train_examples+number_of_test_examples,:]\n",
        "#y_test = target_tr[number_of_train_examples:number_of_train_examples+number_of_test_examples,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQU00n2Gy5P2",
        "outputId": "b715b95c-b2e7-4431-aba1-786493e08a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (3195000, 7)\n",
            "Y_train: (3195000, 3)\n"
          ]
        }
      ],
      "source": [
        "print('X_train: ' + str(X_train.shape))\n",
        "print('Y_train: ' + str(y_train.shape))\n",
        "#print('X_test: ' + str(X_test.shape))\n",
        "#print('Y_test: ' + str(y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qXCYosyMy7Ij"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(43)\n",
        "tf.random.set_seed(43)\n",
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(128)\n",
        "#test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rd7_esGly-hH"
      },
      "outputs": [],
      "source": [
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_hidden4, size_hidden5, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden1: int, size of hidden layer 1\n",
        "    size_hidden2: int, size of hodden layer 2\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input,self.size_hidden1,self.size_hidden2,self.size_hidden3,self.size_hidden4,self.size_hidden5, self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_hidden4, size_hidden5, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden1]))\n",
        "    # Initialize weights between input layer and hidden layer2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden2]))\n",
        "    # Initialize weights between input layer and hidden layer3\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_hidden3]))\n",
        "    # Initialize weights between input layer and hidden layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_hidden4]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_hidden4]))\n",
        "    # Initialize weights between input layer and hidden layer\n",
        "    self.W5 = tf.Variable(tf.random.normal([self.size_hidden4, self.size_hidden5]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b5 = tf.Variable(tf.random.normal([1, self.size_hidden5]))\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W6 = tf.Variable(tf.random.normal([self.size_hidden5, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b6 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.W5, self.W6, self.b1, self.b2, self.b3, self.b4, self.b5, self.b6]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, X, y_pred, y_true, grad_flag,counter):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)\n",
        "\n",
        "    if(grad_flag):\n",
        "      X_tf = tf.Variable(X)\n",
        "      with tf.GradientTape(persistent=True) as tape_outer:\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "          predicted = self.forward(X_tf)\n",
        "          grad_gas = tape.gradient(predicted[0][0],X_tf)\n",
        "          grad_pressure = tape.gradient(predicted[0][1],X_tf)\n",
        "          grad_pressure_coord = grad_pressure[0][1:4]\n",
        "        gravity_vector = [0,0,9.81]\n",
        "        gravity_tensor = tf.cast(tf.convert_to_tensor(gravity_vector),dtype=tf.float64)\n",
        "        process_grav = tf.cast(997*gravity_tensor,dtype=tf.float64)\n",
        "        mult1 = tf.math.subtract(grad_pressure_coord,process_grav)\n",
        "        K_mat = [[X_tf[0][4],0,0],[0,X_tf[0][4],0],[0,0,X_tf[0][4]]]\n",
        "        K_mat_tensor = tf.cast(tf.convert_to_tensor(K_mat), dtype=tf.float64)\n",
        "        mult2 = tf.cast((tf.multiply(K_mat_tensor,mult1)), dtype=tf.float64)\n",
        "        mult3 = tf.multiply(tf.cast(((1-predicted[0][0])/(0.01)),dtype=tf.float64),mult2)\n",
        "        grad_mult3 = tape_outer.gradient(mult3,X_tf)\n",
        "        grad_mult3_extract = grad_mult3[0][1:4]\n",
        "        sum_grad = tf.math.reduce_sum(grad_mult3_extract)\n",
        "      grad_gas_time = grad_gas[0][0]\n",
        "      loss1_val = -grad_gas_time-sum_grad\n",
        "      loss1 = loss1_val*loss1_val\n",
        "\n",
        "    if(grad_flag):\n",
        "      X_tf = tf.Variable(X)\n",
        "      with tf.GradientTape(persistent=True) as tape_outer:\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "          predicted = self.forward(X_tf)\n",
        "          grad_gas = tape.gradient(predicted[0][0],X_tf)\n",
        "          grad_pressure = tape.gradient(predicted[0][1],X_tf)\n",
        "          grad_pressure_coord = grad_pressure[0][1:4]\n",
        "        gravity_vector = [0,0,9.81]\n",
        "        gravity_tensor = tf.cast(tf.convert_to_tensor(gravity_vector),dtype=tf.float64)\n",
        "        process_grav = tf.cast(1.87*gravity_tensor,dtype=tf.float64)\n",
        "        mult1 = tf.math.subtract(grad_pressure_coord,process_grav)\n",
        "        K_mat = [[X_tf[0][4],0,0],[0,X_tf[0][4],0],[0,0,X_tf[0][4]]]\n",
        "        K_mat_tensor = tf.cast(tf.convert_to_tensor(K_mat), dtype=tf.float64)\n",
        "        mult2 = tf.cast((tf.multiply(K_mat_tensor,mult1)), dtype=tf.float64)\n",
        "        mult3 = tf.multiply(tf.cast(((predicted[0][0])/(0.7)),dtype=tf.float64),mult2)\n",
        "        grad_mult3 = tape_outer.gradient(mult3,X_tf)\n",
        "        grad_mult3_extract = grad_mult3[0][1:4]\n",
        "        sum_grad = tf.math.reduce_sum(grad_mult3_extract)\n",
        "      grad_gas_time = grad_gas[0][0]\n",
        "      loss2_val = grad_gas_time-sum_grad\n",
        "      loss2 = loss1_val*loss1_val\n",
        "    \n",
        "    loss_val = tf.cast(tf.losses.mean_squared_error(y_true_tf, y_pred_tf),dtype= tf.float64)\n",
        "    loss12 = tf.math.add(tf.cast(loss2,dtype=tf.float32),tf.cast(loss1,dtype=tf.float32))\n",
        "    loss12 = loss12/3195000\n",
        "\n",
        "    return tf.math.add(tf.cast(loss_val[0],dtype=tf.float32),tf.cast(loss12,dtype=tf.float32))\n",
        "    \n",
        "    \n",
        "\n",
        "  def accuracy(self, y_pred, y_true):\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)\n",
        "    correct_pred = tf.reduce_sum(tf.abs(y_true_tf-y_pred_tf))  \n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
        "    return accuracy\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(inputs,predicted, y_train, True,1)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    \n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    #hhat1_1 = tf.nn.dropout(hhat1, 0.25)\n",
        "    \n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    #hhat2_1 = tf.nn.dropout(hhat2, 0.25)\n",
        "\n",
        "    # Compute values in hidden layer3\n",
        "    what3 = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    hhat3 = tf.nn.relu(what3)\n",
        "    \n",
        "    # Compute values in hidden layer4\n",
        "    what4 = tf.matmul(hhat3, self.W4) + self.b4\n",
        "    hhat4 = tf.nn.relu(what4)\n",
        "\n",
        "    # Compute values in hidden layer5\n",
        "    what5 = tf.matmul(hhat4, self.W5) + self.b5\n",
        "    hhat5 = tf.nn.relu(what5)\n",
        "\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat5, self.W6) + self.b6\n",
        "    output = tf.nn.relu(output)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZPx9eUY0zFzu"
      },
      "outputs": [],
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALQle0KSzI-0",
        "outputId": "24f2fed2-9078-42c2-f636-cba4d0df63c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ]
        }
      ],
      "source": [
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_hidden4, size_hidden5, size_output, device='gpu')\n",
        "\n",
        "# Array to store accuracy and loss\n",
        "loss_with_epoch = []\n",
        "acc_with_epoch = []\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  ac = 0\n",
        "  count = 0\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(1)\n",
        "  counter = 0\n",
        "  for inputs, outputs in train_ds:\n",
        "    grad_flag = True\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(inputs, preds, outputs, grad_flag, counter)\n",
        "    #grad_flag = False\n",
        "    #lt = lt + mlp_on_cpu.loss(inputs, preds, outputs, grad_flag, 1)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    ac = ac+mlp_on_cpu.accuracy(preds, outputs)\n",
        "    #ac = mlp_on_cpu.accuracy(preds, outputs)\n",
        "    count += 1\n",
        "  print('Number of Epoch = {} - Average celoss:= {}- Acc:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0], ac/count))\n",
        "  loss_with_epoch.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  acc_with_epoch.append(ac/count)\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0nNQDOizN59"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11GUe2HpLFEMP0DN1n7CLGcxVO6ccl3UW",
      "authorship_tag": "ABX9TyNq6BwrUqsoHNwFvwNt7kxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}