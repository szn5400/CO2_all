{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szn5400/CO2_all/blob/main/Copy_of_Copy_of_PINN_trial_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrzYQAG_xGuH",
        "outputId": "3e6f1abc-3e31-4e87-af15-d247188432c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All files: ['/content/drive/MyDrive/data/k1r1-h.out', '/content/drive/MyDrive/data/k1r2-h.out', '/content/drive/MyDrive/data/k1r3-h.out', '/content/drive/MyDrive/data/k1r4-h.out', '/content/drive/MyDrive/data/k1r5-h.out', '/content/drive/MyDrive/data/k1r6-h.out', '/content/drive/MyDrive/data/k1r7-h.out', '/content/drive/MyDrive/data/k1r8-h.out', '/content/drive/MyDrive/data/k1r9-h.out', '/content/drive/MyDrive/data/k2r1-h.out', '/content/drive/MyDrive/data/k2r2-h.out', '/content/drive/MyDrive/data/k2r3-h.out', '/content/drive/MyDrive/data/k2r4-h.out', '/content/drive/MyDrive/data/k2r5-h.out', '/content/drive/MyDrive/data/k2r6-h.out', '/content/drive/MyDrive/data/k2r7-h.out', '/content/drive/MyDrive/data/k2r8-h.out', '/content/drive/MyDrive/data/k2r9-h.out', '/content/drive/MyDrive/data/k3r1-h.out', '/content/drive/MyDrive/data/k3r2-h.out', '/content/drive/MyDrive/data/k3r3-h.out', '/content/drive/MyDrive/data/k3r4-h.out', '/content/drive/MyDrive/data/k3r5-h.out', '/content/drive/MyDrive/data/k3r6-h.out', '/content/drive/MyDrive/data/k3r7-h.out', '/content/drive/MyDrive/data/k3r8-h.out', '/content/drive/MyDrive/data/k3r9-h.out']\n",
            "Processing file:  /content/drive/MyDrive/data/k1r1-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r2-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r3-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r4-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r5-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r6-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r7-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r8-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k1r9-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r1-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r2-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r3-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r4-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r5-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r6-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r7-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r8-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k2r9-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r1-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r2-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r3-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r4-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r5-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r6-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r7-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r8-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Processing file:  /content/drive/MyDrive/data/k3r9-h.out\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "0.0 days\n",
            "count: 71\n",
            "Why all 0.0?\n",
            "Ks [[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]]\n",
            "Rs [[0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]\n",
            " [0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]\n",
            " [0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]]\n",
            "debug2: (27, 71, 25, 25, 3)\n",
            "(27, 72, 25, 25, 3)\n",
            "debug2: (27, 71, 25, 25, 3)\n",
            "(27, 72, 25, 25, 3)\n",
            "debug2: (27, 71, 25, 25, 3)\n",
            "(27, 72, 25, 25, 3)\n",
            "debug2: (27, 71, 25, 25, 3)\n",
            "(27, 71)\n",
            "debug2: (27, 71)\n",
            "(27, 71)\n",
            "start\n",
            "end\n",
            "(3594375, 7)\n",
            "(3594375, 3)\n",
            "(3594375, 1)\n",
            "(3594375, 1)\n",
            "(3594375, 1)\n",
            "(3195000, 7)\n",
            "(3195000, 3)\n",
            "(3195000, 1)\n",
            "(3195000, 1)\n",
            "(3195000, 1)\n",
            "(399375, 7)\n",
            "(399375, 3)\n",
            "(399375, 1)\n",
            "(399375, 1)\n",
            "(399375, 1)\n"
          ]
        }
      ],
      "source": [
        "#for mtt (MLP) PINN  \n",
        "\n",
        "#MTT Paper reimplementation with all data taken for rescaling rather than just training data\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/code/MLP')\n",
        "\n",
        "from read_data_unscaled import read\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from read_model import MLP_multiple\n",
        "from data_to_numpy_unscaled import numpy_multi\n",
        "\n",
        "\n",
        "#read data\n",
        "all_pressures,all_saturations,all_permeabilities,all_porosities,all_surf_inj_rate_series,all_surf_prod_rate_series,Ks,Rs = read()\n",
        "\n",
        "#convert to numpy\n",
        "features1_tr,features2_tr,target1_tr,target2_tr,target3_tr,features1_te,features2_te,target1_te,target2_te,target3_te,min_target1,max_target1,min_target2,max_target2,min_target3,max_target3 = numpy_multi(all_pressures,all_saturations,all_permeabilities,all_porosities,all_surf_inj_rate_series,all_surf_prod_rate_series,Ks,Rs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poo9FG_pxSqL",
        "outputId": "b62ad7f9-c5af-4930-a9ad-3d42f080e1ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3195000\n"
          ]
        }
      ],
      "source": [
        "print(len(target3_tr))\n",
        "target_tr = [[0 for j in range(3)] for i in range(len(target1_tr))]\n",
        "for i in range(len(target1_tr)):\n",
        "  target_tr[i][0] = target1_tr[i]\n",
        "  target_tr[i][1] = target2_tr[i]\n",
        "  target_tr[i][2] = target3_tr[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22NTCiAOyS_P",
        "outputId": "7ef215aa-24b5-4be3-eaec-214a130aa57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (3195000, 7)\n",
            "Y_train: (3195000, 3)\n"
          ]
        }
      ],
      "source": [
        "target_tr = np.asarray(target_tr)\n",
        "target_tr = target_tr.reshape(3195000,3)\n",
        "print('X_train: ' + str(features1_tr.shape))\n",
        "print('Y_train: ' + str(target_tr.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_g4MU9gyuwm"
      },
      "outputs": [],
      "source": [
        "size_input = 7\n",
        "size_hidden1 = 32\n",
        "size_hidden2 = 16\n",
        "size_hidden3 = 8\n",
        "size_output = 3\n",
        "number_of_train_examples = 50000\n",
        "number_of_test_examples = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejwJr14vy12O"
      },
      "outputs": [],
      "source": [
        "X_train = features1_tr[:number_of_train_examples,:]\n",
        "y_train = target_tr[:number_of_train_examples,:]\n",
        "X_test = features1_tr[number_of_train_examples:number_of_train_examples+number_of_test_examples,:]\n",
        "y_test = target_tr[number_of_train_examples:number_of_train_examples+number_of_test_examples,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQU00n2Gy5P2",
        "outputId": "3310d28b-d4c9-4251-956d-ebfbd40f5221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (50000, 7)\n",
            "Y_train: (50000, 3)\n",
            "X_test: (1000, 7)\n",
            "Y_test: (1000, 3)\n"
          ]
        }
      ],
      "source": [
        "print('X_train: ' + str(X_train.shape))\n",
        "print('Y_train: ' + str(y_train.shape))\n",
        "print('X_test: ' + str(X_test.shape))\n",
        "print('Y_test: ' + str(y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXCYosyMy7Ij"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(43)\n",
        "tf.random.set_seed(43)\n",
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(128)\n",
        "#test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd7_esGly-hH"
      },
      "outputs": [],
      "source": [
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden1: int, size of hidden layer 1\n",
        "    size_hidden2: int, size of hodden layer 2\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input,self.size_hidden1,self.size_hidden2,self.size_hidden3,self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden1]))\n",
        "    # Initialize weights between input layer and hidden layer2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden2]))\n",
        "    # Initialize weights between input layer and hidden layer3\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_hidden3]))\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4,self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, X, y_pred, y_true, grad_flag,counter):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)\n",
        "\n",
        "    if(grad_flag):\n",
        "      X_tf = tf.Variable(X)\n",
        "      with tf.GradientTape(persistent=True) as tape_outer:\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "          predicted1 = self.forward(X_tf)\n",
        "          predicted = tf.cast(predicted1,dtype = tf.float32)\n",
        "          #x_tf_sqr = tf.multiply(X_tf,X_tf)\n",
        "          #grad_X_sq = tape.gradient(x_tf_sqr,X_tf)\n",
        "          #print('X_val',X_tf)\n",
        "          #print('grad_check',grad_X_sq)\n",
        "          grad_gas = tape.gradient(predicted[0][0],X_tf)\n",
        "          #print('grad_gas', grad_gas)\n",
        "          grad_pressure = tape.gradient(predicted[0][1],X_tf)\n",
        "          #print('grad_pre', grad_pressure)\n",
        "          grad_pressure_coord = grad_pressure[0][1:4]\n",
        "        gravity_vector = [0,0,9.81]\n",
        "        gravity_tensor = tf.cast(tf.convert_to_tensor(gravity_vector),dtype=tf.float64)\n",
        "        process_grav = tf.cast(997*gravity_tensor,dtype=tf.float64)\n",
        "        mult1 = tf.math.subtract(grad_pressure_coord,process_grav)\n",
        "        K_mat = [[X_tf[0][4],0,0],[0,X_tf[0][4],0],[0,0,X_tf[0][4]]]\n",
        "        K_mat_tensor = tf.cast(tf.convert_to_tensor(K_mat), dtype=tf.float64)\n",
        "        mult2 = tf.cast((tf.multiply(K_mat_tensor,mult1)), dtype=tf.float64)\n",
        "        mult3 = tf.multiply(tf.cast(((1-predicted[0][0])/(0.01)),dtype=tf.float64),mult2)\n",
        "        grad_mult3 = tape_outer.gradient(mult3,X_tf)\n",
        "        grad_mult3_extract = grad_mult3[0][1:4]\n",
        "        sum_grad = tf.math.reduce_sum(grad_mult3_extract)\n",
        "      grad_gas_time = grad_gas[0][3]\n",
        "      #print('grad_gas_time', grad_gas_time)\n",
        "      loss1_val = -grad_gas_time-sum_grad\n",
        "      loss1 = loss1_val*loss1_val\n",
        "\n",
        "    if(grad_flag):\n",
        "      X_tf = tf.Variable(X)\n",
        "      with tf.GradientTape(persistent=True) as tape_outer:\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "          predicted1 = self.forward(X_tf)\n",
        "          predicted = tf.cast(predicted1,dtype = tf.float32)\n",
        "          grad_gas = tape.gradient(predicted[0][0],X_tf)\n",
        "          grad_pressure = tape.gradient(predicted[0][1],X_tf)\n",
        "          grad_pressure_coord = grad_pressure[0][1:4]\n",
        "        gravity_vector = [0,0,9.81]\n",
        "        gravity_tensor = tf.cast(tf.convert_to_tensor(gravity_vector),dtype=tf.float64)\n",
        "        process_grav = tf.cast(1.87*gravity_tensor,dtype=tf.float64)\n",
        "        mult1 = tf.math.subtract(grad_pressure_coord,process_grav)\n",
        "        K_mat = [[X_tf[0][4],0,0],[0,X_tf[0][4],0],[0,0,X_tf[0][4]]]\n",
        "        K_mat_tensor = tf.cast(tf.convert_to_tensor(K_mat), dtype=tf.float64)\n",
        "        mult2 = tf.cast((tf.multiply(K_mat_tensor,mult1)), dtype=tf.float64)\n",
        "        mult3 = tf.multiply(tf.cast(((predicted[0][0])/(0.7)),dtype=tf.float64),mult2)\n",
        "        grad_mult3 = tape_outer.gradient(mult3,X_tf)\n",
        "        grad_mult3_extract = grad_mult3[0][1:4]\n",
        "        sum_grad = tf.math.reduce_sum(grad_mult3_extract)\n",
        "      #grad_gas_time = grad_gas[0][0]\n",
        "      grad_gas_time = grad_pressure[0][0]\n",
        "      loss2_val = grad_gas_time-sum_grad\n",
        "      loss2 = loss2_val*loss2_val\n",
        "    \n",
        "    loss_val = tf.cast(tf.losses.mean_squared_error(y_true_tf, y_pred_tf),dtype= tf.float64)\n",
        "    loss12 = tf.math.add(tf.cast(loss2,dtype=tf.float32),tf.cast(loss1,dtype=tf.float32))\n",
        "    #print('loss12',loss12)\n",
        "    loss12 = tf.abs(loss12)\n",
        "    #if(loss12 > 0):\n",
        "      #print('loss12',loss12)\n",
        "    loss12 = loss12/50000\n",
        "\n",
        "    return tf.math.add(tf.cast(loss_val[0],dtype=tf.float32),tf.cast(loss12,dtype=tf.float32))\n",
        "    \n",
        "    \n",
        "\n",
        "  def accuracy(self, y_pred, y_true):\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(tf.reshape(y_pred, (-1, self.size_output)), dtype=tf.float32)\n",
        "    correct_pred = tf.reduce_sum(tf.abs(y_true_tf-y_pred_tf))  \n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
        "    return accuracy\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(inputs,predicted, y_train, True,1)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    \n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    #hhat1_1 = tf.nn.dropout(hhat1, 0.25)\n",
        "    \n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    #hhat2_1 = tf.nn.dropout(hhat2, 0.25)\n",
        "\n",
        "    # Compute values in hidden layer3\n",
        "    what3 = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    hhat3 = tf.nn.relu(what3)\n",
        "\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat3, self.W4) + self.b4\n",
        "    output = tf.nn.relu(output)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPx9eUY0zFzu"
      },
      "outputs": [],
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALQle0KSzI-0",
        "outputId": "c3b58220-3303-498f-f770-c288631a2098"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Epoch = 1 - Average celoss:= 0.533582421875- Acc:= 0.8985335230827332 \n",
            "Number of Epoch = 2 - Average celoss:= 0.17155791015625- Acc:= 0.7454956769943237 \n",
            "Number of Epoch = 3 - Average celoss:= 0.17099052734375- Acc:= 0.7435981035232544 \n",
            "Number of Epoch = 4 - Average celoss:= 0.1703935546875- Acc:= 0.7417894601821899 \n",
            "Number of Epoch = 5 - Average celoss:= 0.1698811328125- Acc:= 0.7399240732192993 \n",
            "Number of Epoch = 6 - Average celoss:= 0.16935853515625- Acc:= 0.7381653189659119 \n",
            "Number of Epoch = 7 - Average celoss:= 0.1689305078125- Acc:= 0.7367292046546936 \n",
            "Number of Epoch = 8 - Average celoss:= 0.168684296875- Acc:= 0.735835611820221 \n",
            "Number of Epoch = 9 - Average celoss:= 0.16848916015625- Acc:= 0.7351582050323486 \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-36b284e8a6f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#grad_flag = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#lt = lt + mlp_on_cpu.loss(inputs, preds, outputs, grad_flag, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmlp_on_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmlp_on_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#ac = mlp_on_cpu.accuracy(preds, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-e4e90f76188f>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m       \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m       \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-e4e90f76188f>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, X, y_pred, y_true, grad_flag, counter)\u001b[0m\n\u001b[1;32m     64\u001b[0m           \u001b[0mgrad_gas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m           \u001b[0;31m#print('grad_gas', grad_gas)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m           \u001b[0mgrad_pressure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m           \u001b[0;31m#print('grad_pre', grad_pressure)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m           \u001b[0mgrad_pressure_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_pressure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_ReluGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ReluGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mrelu_grad\u001b[0;34m(gradients, features, name)\u001b[0m\n\u001b[1;32m  10718\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10719\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10720\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m  10721\u001b[0m         _ctx, \"ReluGrad\", name, gradients, features)\n\u001b[1;32m  10722\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "\n",
        "# Array to store accuracy and loss\n",
        "loss_with_epoch = []\n",
        "acc_with_epoch = []\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  ac = 0\n",
        "  count = 0\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(1)\n",
        "  counter = 0\n",
        "  for inputs, outputs in train_ds:\n",
        "    grad_flag = True\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(inputs, preds, outputs, grad_flag, counter)\n",
        "    #grad_flag = False\n",
        "    #lt = lt + mlp_on_cpu.loss(inputs, preds, outputs, grad_flag, 1)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    ac = ac+mlp_on_cpu.accuracy(preds, outputs)\n",
        "    #ac = mlp_on_cpu.accuracy(preds, outputs)\n",
        "    count += 1\n",
        "  print('Number of Epoch = {} - Average celoss:= {}- Acc:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0], ac/count))\n",
        "  fopen = open('data_epoch.txt','w')\n",
        "  fopen.write(str(epoch))\n",
        "  fopen.write(str(np.sum(loss_total) / X_train.shape[0]))\n",
        "  fopen.close()\n",
        "  loss_with_epoch.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  acc_with_epoch.append(ac/count)\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q0nNQDOizN59"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1gOXjn0rL3StT0aSXeDpoYgSM38Xp9sf7",
      "authorship_tag": "ABX9TyMDh7VFSLfU+DE4tF0l2Xde",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}